\newpage
\begin{center}
  \textbf{\large 1. Аналитический обзор }
\end{center}
\refstepcounter{chapter}
\addcontentsline{toc}{chapter}{1. Аналитический обзор }

% \section{Существующие подходы визуальной одометрии}
% \section{Технологии одометрии и SLAM на базе лидаров}
% \section{Мультимодальные системы: общие принципы совмещения визуальных и лидарных данных}
% \section{Анализ современных решений и библиотек}

\section{Существующие подходы монокулярной визуальной одометрии и SLAM}
Задача визуальной одометрии (ВО) состоит в оценке траектории движения камеры 
$\mathcal{T}_{VO}$ путём анализа последовательности изображений 
$\{I_k\}_{0:K}$. SLAM (Simultaneous navigation and mapping) предполагает 
построение глобальной карты, а также проведение дополнительных оптимизаций траектории.
Сама траектория представляет из себя набор положений камеры 
в обозначенной глобальной системе координат:
\begin{equation}
    \mathcal{T}_{VO} = \{C_k\}_{0:K},
\end{equation}
где $C_k$ --- положение камеры в момент $k$. Чаще всего глобальная 
система координат выбирается согласно первому положению камеры в 
последовательности.

В качестве подзадачи рассматривается оценка пространственной трансформации 
между последующими положениями камеры $T_k^{k-1}$ на основе кадров $I_{k-1}$ 
и $I_k$.
\begin{equation}
    T_k^{k-1} = \begin{bmatrix}R_k^{k-1} & t_k^{k-1} \\ 0 & 1\end{bmatrix},
\end{equation}
где $R_k^{k-1} \in \mathbb{R}^{3\times 3}$, $t_k^{k-1} \in \mathbb{R}^3$ --- 
матрица поворота и вектор смещения между кадрами соответственно. Можем выразить 
положения камеры следующим образом:
\begin{equation}
    C_k = \prod\limits_{i=1}^k T_i^{i-1}
\end{equation}

Положим, что соседние кадры $I_{0}$ и $I_1$ содержат наборы соответствующих друг 
другу точек в однородной системе координат $\{p^1_i\} \in \mathbb{R}^3$ и 
$\{p^{0}_i\} \in \mathbb{R}^3$. Тогда, выполнено эпиполярное ограничение 
с нормализацией:
\begin{equation}
    p^{1\top}_i K_c^{-\top} E K_c^{-1} p^{0}_i=0,
\end{equation}
где $K_c \in \mathbb{R}^{3\times 3}$ --- матрица калибровки камеры (camera matrix), 
$E\in \mathbb{R}^{3\times 3}$ --- эссенциальная матрица (essential matrix).

Существуют методы, позволяющие оценить значение эссенциальной матрицы, на 
основе наборов точек $\{p^1_i\}$ и $\{p^{0}_i\}$. Наиболее популярными являются 
восьмиточечный и пятиточечный алгоритмы. Часто для улучшения качества оценки применяется RANSAC.

На основе полученной оценки эссенциальной матрицы возможно восстановить взаимную
ориентацию камер, а также направление смещения. Важно заметить, что в постановке 
задачи монокулярной одометрии невозможно оценить метрическое значение вектора смещения
без дополнительной информации. Кроме того, ориентация и направление восстанавливаются
не единственным способом:
\begin{equation}
R^{0}_1 = UWC^\top, t^{0}_1 = \pm u_3 \vee R^{0}_1 = UW^\top C^\top, t^{0}_1 = \pm u_3,
\end{equation}
где $U$, $V$ --- матрицы правых и левых сингулярных векторов в разложении $E$, $W = \begin{bmatrix}
    0 & -1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1
\end{bmatrix}$, $u_3$ --- третий столбец матрицы $U$. Т.к. значение длины вектора $t^{0}_1$
невозможно восстановить на данном этапе, обычно оно принимается равным $1$.

Так как полученная оценка неоднозначна, требуется дополнительная валидация. Наиболее
распространенным подходом является триангуляция с целью получения оценок 
пространственных координат соответствующих точек. Выбирается конфигурация, обеспечивающая
валидное положение точек относительно камеры, а именно --- точки должны находится перед 
камерами (не иметь отрицательную глубину). Полученная конфигурация положений камеры и
точек в пространстве позволят построить базовую 3D карту.

Для сохранения единого масштаба, начиная с обработки 3 кадра применяются методы 2D-3D 
сопоставления при оценке последующих трансформаций (после первой итерации и триангуляции получены
3D координаты сопоставляемых точек). Наиболее широко используемыми являются методы 
EPnP, UPnP и OPnP. 

Выше указанные методы склонны к быстрому накоплению ошибок, что приводит к искажению 
масштаба и структуры. Возможным решением является применение алгоритма групповой корректировки
(Bundle Adjustment), решающего оптимизационную задачу минимизации ошибки перепроецирования 
путем восстановления одновременно положений камер и точек. Ранее оцененная структура
используется в качестве начальных условий. Такой подход позволяет значительно повысить
устойчивость и качество оценок, однако требует значительных вычислительных ресурсов. 
В связи с этим, групповая корректировка обычно применяется с частотой меньшей, чем предыдущие
шаги.

Рассмотренный выше подход является общим для большинства методов визуальной одометрии. 
Его схема представлена на рисунке \textbf{TODO!!!}. При дальнейшем описании методов
сделан акцент на ключевые отличия или особенности, заключающиеся в 
деталях реализации таких как способы детекции и сопоставления статичных точек, 
восстановления масштаба с использованием семантической информации, модификации 
оптимизационных задач.

\subsection{Методы на основе ключевых точек (feature-based)}
Большую часть методов визуальной одометрии на данный момент составляют методы на 
основе ключевых точек. Идея состоит в детекции устойчивых точек, обладающих важной 
семантической или геометрической информацией и дальнейшее сопоставление их 
между кадрами. В остальном зачастую процесс следует общей методологии. 

Семейство методов ORB-SLAM --- это один из наиболее известных и эффективных методов визуальной 
одометрии и построения карт. Их подход к монокулярной одометрии включает в себя три основных модуля: 
\begin{enumerate}
    \item трекинг;
    \item создание карты;
    \item замыкание цикла.
\end{enumerate}
Трекинг осуществляется путем выделения бинарных ORB-дескрипторов на изображении и применении 
процедуры ассоциации данных на основе расстояния Хэмминга. Для задачи замыкания
цикла производится сопоставление наблюдаемых ключевых точек с сохраненными в карте.
С помощью метода Bag of Words проверяются гипотезы о совпадении. При обнаружении совпадения
производится глобальная оптимизация на позиционном графе --- данная процедура схожа с 
групповой корректировкой, однако оптимизация производится только по отношению к
положениям камеры, а не камеры и точек.

PLP-SLAM использует помимо визуальных признаков также геометрические в виде линий,
которые извлекаются с помощью LSD и преобразуются в LBD-дескрипторы. Таким образом
в ассоциации данных участвуют также признаки, обладающие важной геометрической информацией.
Кроме того, система становится более устойчива и модули локальной групповой корректировки, а также
замыкания цикла работают эффективнее.


\subsection{Прямые методы (direct)}
Прямые методы не используют дискретный набор точек-признаков. Вместо этого, их главная
идея заключается в оптимизации значения фотометрической ошибки на основе интенсивности точек при их проецировании на изображения. 
Таким образом прямые методы сводят задачу 2D-3D сопоставления к чисто оптимизационной.


Широко известным прямым методом является DSO (Direct Sparse Odometry). Суть заключается
в выборе подмножества точек с сильным градиентом интенсивности. Каждой точке 
присваивается значение глубины $d$. Выбирается последовательность ключевых кадров.
Общая функция ошибки по всем кадрам в скользящем окне и точкам:
\begin{equation}
    \mathcal{E} = 
    \sum_{i \in \mathcal{F}} \sum_{j \in \mathcal{N}(i)} 
    \sum_{{p}_i \in P_i}
    w_{i,j}({p}_i) \rho\!\Bigl(\,
    I_j(\pi({T}_j^i {x}_i)) - I_i({p}_i)
    \Bigr),
\end{equation}
где  $\mathcal{F}$ --- множество ключевых кадров в окне оптимизации, $\mathcal{N}(i)$ ---
множество соседних ключевых кадров к $i$, $P_i$ --- набор разреженных 
точек в кадре $i$ (по принципу сильного градиента), $w_{i,j}({p}_i)$ --- 
весовой коэффициент, $\rho(\cdot)$ --- робастная функция потерь (например, 
Хубера или Коши), $\pi(\mathbf{x})$ --- оператор перспективной проекции 
3D-точки $x$ в 2D-координаты на изображении. Путем последовательного решения оптимизационной
задачи $\min\limits_{d, T}(\mathcal{E})$ восстанавливаются глубины точек и взаимные расположения 
камеры. Данный подход демонстрирует высокую точность, сопоставимую с
методами на основе ключевых точек, однако требует значительных вычислительных ресурсов.
Кроме того, в окружениях с отсутствием текстурированных поверхностей прямые являются
более устойчивыми. К их слабым сторонам можно отнести чувствительность к резким изменениям интенсивности.

\subsection{Нейросетевые методы}
В последнее время широкую популярность набирают нейросетевые методы монокулярной
визуальной одометрии. Существует множество их разновидностей, предлагающих различные
способы интеграции нейросетей в данную задачу. Такие методы как SuperPoint SLAM, Droid slam
используют нейросетевые дескрипторы для определения целевых точек. В методе SuperVO используется
графовая нейронная сеть для построения ассоциаций между детектированными признаками. 
Некоторые подходы,такие как Dyna-VO используют нейросети в качестве модуля сегментации
движущихся объектов, что позволяет избегать формирования признака на них и значительно 
повысить робастность.

Особый интерес представляют нейросетевые методы, решающие задачу целиком. MagicVO обладает
сверточно-рекуррентной архитектурой с механизмами внимания, позволяющей эффективно 
анализировать визуально-временную информацию. Обучение предполагается проводить напрямую
на наборах данных с сопоставлением реального перемещения камеры. Стоит отметить, что
итоговый выход модели соответствует реальному масштабу в отличие от большинства рассмотренных
выше методов. 

\section{Технологии одометрии и SLAM на базе лидаров}
\section{Мультимодальные системы: общие принципы совмещения визуальных и лидарных данных}
\section{Анализ современных решений и библиотек}












% \subsection{Принципы на базе ключевых точек}
% Один из распространённых подходов к монокулярной визуальной одометрии — поиск 
% и сопоставление ключевых точек (feature-based). В каждом кадре (кадре $I_t$) 
% детектируются визуально выразительные точки (SIFT, ORB и т. д.), для которых 
% вычисляются дескрипторы $\mathbf{d}_i$. Далее, сопоставляя дескрипторы с точками 
% на следующем кадре $I_{t+1}$, можно приблизительно восстановить 2D-смещение. 
% Известная модель жёсткого движения камеры в пространстве даёт возможность перейти 
% к оценке 3D-трансформации:  
% \begin{equation}
% \{\hat{\mathbf{R}}, \hat{\mathbf{t}}\} = \arg \min_{\mathbf{R}, \mathbf{t}} \sum_i \rho \bigl(\| \mathbf{x}'_i - \pi(\mathbf{R},\mathbf{t}, \mathbf{X}_i)\|\bigr),
% \end{equation}
% где $\pi(\cdot)$ — проекция 3D-точки $\mathbf{X}_i$ на изображение, 
% а $\rho(\cdot)$ — некоторая функция потерь (например, Huber).

% Среди ярких примеров таких систем — ORB-SLAM, VINS-Mono \cite{pixels2precision}. 
% Их преимущество — относительная простота, возможность работы в реальном времени. 
% Недостатки: уязвимость к скудной текстуре, а также неопределённость масштаба в 
% случае монокулярной камеры.

% \subsection{Прямые методы (Direct VO)}
% Помимо ключевых точек, существует класс подходов, который напрямую минимизирует фотометрическую ошибку между последовательными кадрами \cite{monocularVOreview}. Идея состоит в том, чтобы, имея оценку начальной глубины (либо зная её приблизительно, либо постепенно накапливая её по мере движения), подбирать такую трансформацию в 3D (поворот и смещение), которая минимизирует разницу интенсивностей пикселей при наложении изображений друг на друга. Прямые методы обычно хорошо работают при малых перемещениях, где нет слишком сильных изменений параллакса, и позволяют получать более плотную оценку движения \cite{pixels2precision}. Однако они, как правило, требуют качественной начальной калибровки камеры и чувствительны к любым резким засветкам, бликам и изменению экспозиции.

% \subsection{Особенности монокулярной и стерео-VO}
% При использовании \textit{монокулярной} камеры возникает проблема неопределённости масштаба (scale ambiguity) \cite{monocularVOreview}. Любые трансляции в плоскости переносятся в 3D-движение с некоторым неизвестным масштабным коэффициентом, который приходится отслеживать (например, с помощью дополнительной оптимизации или введения априорных предположений). Стереопара камер позволяет частично избавиться от этой проблемы, поскольку между двумя объективами есть известное базовое расстояние (baseline), и глубина может вычисляться напрямую \cite{practicalVOautonomousDriving}. Тем не менее, стереосистемы дороже и сложнее калибровать.

% \subsection{Варианты использования глубины из внешних источников}
% Отдельно можно упомянуть методы, где глубина берётся не только из параллакса при стерео: существуют решения, совмещающие монокулярную камеру и дополнительные источники (например, \textit{анализ движения} на старте или использование IMU) для устранения неоднозначности масштаба \cite{monocularVOreview}. Эти подходы близки к мультимодальным системам, о которых пойдёт речь далее, но опираются в первую очередь на визуальную составляющую.

% Таким образом, визуальная одометрия продолжает развиваться в направлении более устойчивой работы в сложных сценариях. Особое внимание уделяется улучшению вычислительной эффективности (для работы в реальном времени) и учёту различных негативных факторов: изменения освещённости, динамических объектов в кадре, текстурно-пустых областей \cite{pixels2precision}.

% \section{Технологии одометрии и SLAM на базе лидаров}
% Лидарная одометрия (LiDAR Odometry, LO) использует трёхмерные облака точек, получаемые от лазерного дальномера. В отличие от камеры, лидар непосредственно предоставляет геометрию окружающей среды, и его точность в измерении расстояния зачастую выше, чем глубина, получаемая из стереоизображений \cite{lidarOdometrySurvey, lidarMethodologiesSurvey}.

% \subsection{Общие принципы лидарной одометрии}
% Классические алгоритмы лидарной одометрии основываются на регистрации последовательных облаков точек (Iterative Closest Point -- ICP или его модификации) \cite{lidarOdometrySurvey}. Если обозначить скан в момент времени $t$ за $P_t$, а предыдущий скан за $P_{t-1}$, то задача сводится к нахождению преобразования (поворота и смещения) $\mathbf{T}$, которое минимизирует расстояния между точками из $P_t$ и соответствующими точками из $P_{t-1}$. Иногда применяется <<feature-based>> стратегия, в которой из облака точек выделяются характерные структуры (например, плоскости или края), и сравниваются только соответствия между ними \cite{lidarOdometrySurvey}.

% \subsection{Трёхмерные SLAM-системы на базе лидаров}
% Многие решения для лидарного SLAM (Simultaneous Localization and Mapping) также включают карту окружающего пространства, которая постепенно достраивается по мере движения \cite{lidarMethodologiesSurvey}. Среди популярных примеров -- LOAM (LiDAR Odometry and Mapping), Cartographer, SuMa и др. \cite{lidarOdometrySurvey}. Ценность таких систем заключается в том, что они позволяют не только отслеживать траекторию, но и строить подробную 3D-карту, которая может использоваться для навигации.

% \subsection{Проблемы и вызовы}
% Хотя лидар обеспечивает независимость от освещения и иногда даёт очень плотное облако точек, есть ситуации, где он может столкнуться с трудностями:
% \begin{itemize}
%     \item \textbf{Сцены с дефицитом геометрических особенностей}, например, длинные коридоры без выступов, где ICP и подобные алгоритмы испытывают <<выскальзывание>> (drift).
%     \item \textbf{Засорённость или сильное динамическое окружение}, где облака точек содержат много подвижных объектов (люди, автомобили). Это затрудняет поиск соответствий.
%     \item \textbf{Погрешности при очень большом расстоянии}, так как дальнобойность лидара высока, но шум также возрастает.
% \end{itemize}
% Тем не менее, лидарная одометрия обладает высокой точностью и устойчивостью в большинстве <<типичных>> уличных/открытых сценариев. Именно поэтому данный подход успешно применяется в автомобилях с системами автономного вождения \cite{lidarMethodologiesSurvey}.

% \section{Мультимодальные системы: общие принципы совмещения визуальных и лидарных данных}
% Как отмечается в ряде исследований \cite{pixels2precision, lidarOdometrySurvey}, объединение камеры и лидара (sensor fusion) даёт взаимную компенсацию недостатков. Лидар хорошо определяет геометрию сцены, но <<слеп>> к цвету и текстурам, тогда как визуальная камера богата на текстурную информацию, но не всегда даёт прямые расстояния.

% \subsection{Варианты интеграции (loosely-coupled и tightly-coupled)}
% Существует два основных способа объединения данных лидара и камеры \cite{lidarMethodologiesSurvey}:
% \begin{enumerate}
%     \item \textbf{Loosely-coupled (слабо связанная)}: каждый сенсор обрабатывается отдельным алгоритмом (лидарная одометрия + визуальная одометрия), а результаты (оценки позы) комбинируются в фильтре (EKF, UKF) или в другом механизме. Это проще, но может упускать часть информации, ведь сенсоры работают <<параллельно>> и не обмениваются детальными признаками.
%     \item \textbf{Tightly-coupled (тесно связанная)}: строится общий алгоритм (чаще всего оптимизационный или фильтрационный), где одновременно учитываются ограничения из облаков точек и из изображений. Это сложнее, но даёт прирост точности и робастности.
% \end{enumerate}

% В более современных системах применяются фактор-графы, где узлы соответствуют состояниям робота (позам), а факторы (ограничения) исходят как от лидара, так и от камеры. Таким образом, если лидар <<теряется>> в коридоре, визуальная составляющая помогает удержаться, и наоборот \cite{practicalVOautonomousDriving}.

% \subsection{Sensor fusion на уровне данных}
% Многие современные методы пытаются <<проектировать>> облака точек на изображение или, наоборот, привязывать пиксели к 3D-точкам. Таким образом, получают дополнительную информацию о глубине для каждого пикселя (пусть и разреженную), либо визуальные дескрипторы для лидарных точек \cite{pixels2precision}. Цель -- сформировать более информативные признаки, чтобы улучшать поиск соответствий и минимизировать Drift.

% \subsection{Использование глубокого обучения}
% Отдельное направление исследований -- нейросетевые модели, где фьюзинг лидара и камеры происходит через многослойные архитектуры. Они могут напрямую оценивать относительное движение (VO) или формировать промежуточные карты глубины/облака точек. Хотя такие методы пока в меньшинстве и сложны в обучении, некоторые результаты показывают высокую точность даже в неидеальных условиях \cite{pixels2precision}.

% \section{Анализ современных решений и библиотек}
% В последние годы появилось несколько обзоров, затрагивающих как чисто визуальную, так и лидарную одометрию, а также их совмещение:
% \begin{itemize}
%     \item \textbf{Обзор монокулярных методов ВО} \cite{pixels2precision, monocularVOreview}, где подчёркиваются проблемы масштаба и указываются способы повышения точности за счёт калибровки и внутренних моделей камеры.
%     \item \textbf{Обзоры лидарной одометрии} \cite{lidarOdometrySurvey, lidarMethodologiesSurvey}, освещающие классические ICP-базированные подходы, методы, основанные на выделении ключевых геометрических признаков, а также SLAM-системы, строящие глобальные карты.
%     \item \textbf{Заметки по интегрированным системам} в контексте автономного вождения, где лидар и камера объединяются для достижения высокой надёжности в самых разнообразных погодных и дорожных условиях \cite{practicalVOautonomousDriving}.
% \end{itemize}

% Кроме того, существует ряд открытых библиотек, реализующих мультимодальный SLAM или одометрию. Некоторые из них ориентированы на ROS, другие реализованы в виде отдельных C++/Python-пакетов. Для экспериментов с KITTI, как правило, используются хорошо зарекомендовавшие себя фреймворки, обеспечивающие удобный доступ к калиброванным данным камеры и лидара \cite{practicalVOautonomousDriving, monocularVOreview}.

% Наиболее существенные сложности при работе с реальным фьюзингом возникают из-за необходимости точной синхронизации временных меток и корректной пространственной калибровки (extrinsic parameters). В обзоре \cite{lidarOdometrySurvey} подчёркивается, что даже небольшая ошибка во взаимном расположении лидара и камеры может снизить эффективность мультимодального подхода. Поэтому разработчики систем часто вынуждены разрабатывать свои инструменты и методики для совместной калибровки, либо использовать заранее откалиброванные наборы данных (как KITTI).

% Таким образом, по данным рассмотренных источников, мультимодальные методы одометрии являются перспективным направлением, позволяющим добиться более высокой точности и робастности в сравнении с раздельным использованием камеры или лидара. В то же время, на практике важны вопросы вычислительной эффективности и надёжной калибровки, а также умение корректно обрабатывать динамические сцены и прочие <<нестандартные>> ситуации. Эти аспекты и будут рассмотрены далее при выборе и обосновании конкретного подхода к визуально-лидарной одометрии для мобильных роботов.
